# Como Executar o Projeto

Este guia completo mostra como executar o projeto ETL de cl√≠nicas odontol√≥gicas do in√≠cio ao fim.

## Pr√©-requisitos

Antes de come√ßar, certifique-se de ter instalado:

- Python 3.9+
- Docker e Docker Compose
- Git
- Azure CLI (para deploy na nuvem)
- Terraform (para infraestrutura)

## Configura√ß√£o Inicial

### 1. Clone e Configure o Projeto

```bash
# Clonar o reposit√≥rio
git clone https://github.com/lugialo/ex-etl-engdados.git
cd ex-etl-engdados

# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/macOS
# ou .\venv\Scripts\activate  # Windows

# Instalar depend√™ncias
pip install -r requirements.txt
```

### 2. Configurar Vari√°veis de Ambiente

```bash
# Copiar arquivo de exemplo
cp .env.example .env

# Editar configura√ß√µes (use seu editor preferido)
nano .env
```

**Configura√ß√£o m√≠nima para execu√ß√£o local:**
```bash
# Configura√ß√µes do PostgreSQL (usando Docker)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=clinica_odonto
DB_USER=root
DB_PASSWORD=root

# Azure Storage (opcional - deixe vazio para usar apenas localmente)
AZURE_STORAGE_CONNECTION_STRING=
AZURE_CONTAINER_NAME=landingzone
```

### 3. Subir o Banco de Dados

```bash
# Subir PostgreSQL via Docker
cd docker
docker-compose up -d
cd ..

# Verificar se est√° rodando
docker-compose -f docker/docker-compose.yml ps
```

### 4. Criar Estrutura do Banco

```bash
# Executar scripts de cria√ß√£o
psql -h localhost -U root -d clinica_odonto -f scripts/modelo_fisico.sql
psql -h localhost -U root -d clinica_odonto -f scripts/modelo_dimensional.sql
```

## Execu√ß√£o do Pipeline

### Op√ß√£o 1: Execu√ß√£o Completa Automatizada

```bash
# Gerar dados e executar todo o pipeline
python scripts/gerador_dados.py

# Abrir Jupyter Lab
jupyter lab

# Executar notebooks na ordem:
# 1. notebook_landing_bronze.ipynb
# 2. notebook_bronze_silver.ipynb  
# 3. notebook_silver_gold.ipynb
```

### Op√ß√£o 2: Execu√ß√£o Passo a Passo

#### Passo 1: Gerar Dados Brutos

```bash
python scripts/gerador_dados.py
```

**O que acontece:**
- ‚úÖ Conecta ao banco PostgreSQL
- ‚úÖ Cria e popula tabelas com dados sint√©ticos
- ‚úÖ Exporta dados para CSV na pasta `data/raw/`
- ‚úÖ Upload para Azure Storage (se configurado)
- ‚úÖ Logs detalhados do processo

#### Passo 2: Landing ‚Üí Bronze

```bash
jupyter lab notebooks/notebook_landing_bronze.ipynb
```

**O que acontece:**
- üìÇ L√™ CSVs da pasta `data/raw/`
- üîß Aplica tipagem b√°sica aos dados
- üíæ Salva dados estruturados em `data/bronze/`

#### Passo 3: Bronze ‚Üí Silver

```bash
jupyter lab notebooks/notebook_bronze_silver.ipynb
```

**O que acontece:**
- üßπ Limpa e valida dados
- üîÑ Padroniza formatos
- ‚úÖ Remove duplicatas e inconsist√™ncias
- üíæ Salva dados limpos em `data/silver/`

#### Passo 4: Silver ‚Üí Gold

```bash
jupyter lab notebooks/notebook_silver_gold.ipynb
```

**O que acontece:**
- üìä Agrega dados por dimens√µes de neg√≥cio
- üèóÔ∏è Cria modelo dimensional (fatos e dimens√µes)
- üíæ Carrega dados no Data Warehouse (PostgreSQL)
- üíæ Salva agrega√ß√µes em `data/gold/`

## Valida√ß√£o dos Resultados

### Verificar Dados Gerados

```bash
# Ver arquivos CSV criados
ls -la data/raw/

# Ver estrutura das camadas
tree data/
```

### Consultar Banco de Dados

```bash
# Conectar ao banco
psql -h localhost -U root -d clinica_odonto

# Exemplos de queries
SELECT COUNT(*) FROM dim_paciente;
SELECT COUNT(*) FROM fato_consulta;
SELECT * FROM dim_tempo LIMIT 5;
```

### Verificar Logs

```bash
# Ver logs do Docker
docker-compose -f docker/docker-compose.yml logs -f

# Ver logs do gerador de dados
# (logs s√£o exibidos no terminal durante execu√ß√£o)
```

## Execu√ß√£o com Azure (Opcional)

### 1. Deploy da Infraestrutura

```bash
# Fazer login na Azure
az login

# Configurar Terraform
cd terraform
terraform init
terraform plan
terraform apply

# Obter connection string
terraform output -raw storage_connection_string
```

### 2. Atualizar Configura√ß√£o

```bash
# Atualizar .env com credenciais da Azure
AZURE_STORAGE_CONNECTION_STRING="DefaultEndpointsProtocol=https;AccountName=..."
AZURE_CONTAINER_NAME=landingzone
```

### 3. Executar com Azure Storage

```bash
# Gerar dados (agora com upload para Azure)
python scripts/gerador_dados.py

# Os CSVs ser√£o salvos localmente E na Azure
```

## Monitoramento e Debugging

### Verificar Status dos Servi√ßos

```bash
# Docker
docker-compose -f docker/docker-compose.yml ps

# Conectividade com banco
python scripts/teste_db.py

# Azure Storage (se configurado)
az storage container list --connection-string "sua_connection_string"
```

### Logs Detalhados

```bash
# Logs do PostgreSQL
docker-compose -f docker/docker-compose.yml logs db

# Logs espec√≠ficos do gerador
python scripts/gerador_dados.py 2>&1 | tee gerador.log
```

### Resolver Problemas Comuns

#### Erro de Conex√£o com Banco
```bash
# Verificar se container est√° rodando
docker ps | grep postgres

# Reiniciar se necess√°rio
docker-compose -f docker/docker-compose.yml restart
```

#### Erro de Permiss√£o no Azure
```bash
# Verificar login
az account show

# Verificar acesso ao storage
az storage account show --name seu_storage_account
```

#### Erro de Depend√™ncias Python
```bash
# Reinstalar depend√™ncias
pip install -r requirements.txt --force-reinstall

# Verificar vers√µes
pip list | grep -E "(pandas|sqlalchemy|azure)"
```

## Performance e Otimiza√ß√£o

### Configura√ß√µes para Datasets Maiores

No arquivo `scripts/gerador_dados.py`, ajuste:

```python
# Aumentar n√∫mero de registros
NUM_ENDERECOS = 50000
NUM_PACIENTES = 100000
NUM_CONSULTAS = 500000
```

### Paraleliza√ß√£o com Databricks

1. Deploy infraestrutura Terraform
2. Configure cluster Databricks
3. Upload notebooks para Databricks
4. Execute com maior poder computacional

## Documenta√ß√£o e Visualiza√ß√£o

### Gerar Documenta√ß√£o

```bash
# Servidor local da documenta√ß√£o
mkdocs serve

# Acesse: http://127.0.0.1:8000
```

### Build para Produ√ß√£o

```bash
# Build est√°tico
mkdocs build

# Deploy para GitHub Pages
mkdocs gh-deploy
```

## Limpeza do Ambiente

### Parar Servi√ßos

```bash
# Parar Docker
docker-compose -f docker/docker-compose.yml down

# Desativar ambiente virtual
deactivate
```

### Limpeza Completa

```bash
# Remover dados locais
rm -rf data/bronze/ data/silver/ data/gold/

# Remover volumes Docker
docker-compose -f docker/docker-compose.yml down -v

# Destruir infraestrutura Azure
cd terraform
terraform destroy
```