# Gera√ß√£o de Dados Brutos

O primeiro passo no nosso pipeline ETL √© a gera√ß√£o de uma massa de dados simulada que servir√° como as fontes de dados brutas para o projeto. Este processo √© executado atrav√©s do script Python `scripts/gerador_dados.py`, que foi significativamente aprimorado com novas funcionalidades.

## Prop√≥sito

* **Simula√ß√£o de Fontes:** Criar um conjunto de dados realistas que imitam as opera√ß√µes de uma cl√≠nica odontol√≥gica, permitindo o desenvolvimento e teste do pipeline ETL sem depender de dados sens√≠veis ou complexos de sistemas reais.
* **Volumetria e Variedade:** Gerar um volume consider√°vel de dados e uma variedade de entidades para demonstrar a capacidade do pipeline em lidar com diferentes tipos de informa√ß√£o e escala.
* **Integra√ß√£o Completa:** Conectar diretamente com banco de dados PostgreSQL e Azure Storage para simular um ambiente de produ√ß√£o.

## Novas Funcionalidades (Vers√£o 2.0)

### üîÑ Integra√ß√£o com Banco de Dados
- **Conex√£o PostgreSQL**: Conecta automaticamente com o banco usando SQLAlchemy
- **Cria√ß√£o de Tabelas**: Cria estrutura completa do modelo f√≠sico
- **Popula√ß√£o Autom√°tica**: Insere dados diretamente nas tabelas
- **Limpeza Inteligente**: Remove dados antigos antes de gerar novos

### ‚òÅÔ∏è Integra√ß√£o com Azure Storage
- **Upload Autom√°tico**: Envia CSVs para Azure Blob Storage
- **Configura√ß√£o Flex√≠vel**: Usa vari√°veis de ambiente para credenciais
- **Estrutura Organizada**: Cria hierarquia de pastas apropriada

### üîß Configura√ß√£o via Ambiente
- **Arquivo .env**: Configura√ß√µes centralizadas
- **Flexibilidade**: Suporte a diferentes ambientes (dev, prod)
- **Seguran√ßa**: Credenciais n√£o ficam no c√≥digo

### üìä Logging e Monitoramento
- **Logs Detalhados**: Acompanhe cada etapa do processo
- **Tratamento de Erros**: Mensagens claras em caso de problemas
- **Progresso Visual**: Indicadores de progresso para opera√ß√µes longas

## Ferramentas Utilizadas

* **Script Python:** `scripts/gerador_dados.py`
* **Bibliotecas:**
  - `Faker`: Gera√ß√£o de dados fict√≠cios realistas
  - `SQLAlchemy`: Conex√£o e opera√ß√µes com banco de dados
  - `Azure Storage Blob`: Upload para nuvem Azure
  - `python-dotenv`: Gerenciamento de vari√°veis de ambiente
  - `logging`: Sistema de logs robusto

## Entidades Geradas

O script `gerador_dados.py` cria dados para as seguintes entidades:

| Entidade | Arquivo CSV | Descri√ß√£o |
|----------|-------------|-----------|
| `endereco` | `endereco.csv` | Dados de endere√ßo (CEP, rua, cidade, estado) |
| `odontologista` | `odontologista.csv` | Profissionais (nome, CRO, especialidade) |
| `paciente` | `paciente.csv` | Pacientes (nome, CPF, telefone, email) |
| `tipo_pagamento` | `tipo_pagamento.csv` | M√©todos de pagamento (cart√£o, dinheiro, PIX) |
| `procedimento` | `procedimento.csv` | Cat√°logo de procedimentos odontol√≥gicos |
| `agendamento` | `agendamento.csv` | Agendamentos de consultas |
| `consulta` | `consulta.csv` | Consultas realizadas |
| `consulta_procedimento` | `consulta_procedimento.csv` | Rela√ß√£o consulta √ó procedimento |
| `pagamento` | `pagamento.csv` | Registros de pagamentos |
| `log_pagamento` | `log_pagamento.csv` | Logs de transa√ß√µes |

## Configura√ß√£o

### 1. Vari√°veis de Ambiente

Configure o arquivo `.env`:

```bash
# Banco de Dados PostgreSQL
DB_HOST=localhost
DB_PORT=5432
DB_NAME=clinica_odonto
DB_USER=root
DB_PASSWORD=root

# Azure Storage (opcional)
AZURE_STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=https;AccountName=...
AZURE_CONTAINER_NAME=landingzone
```

### 2. Par√¢metros de Volume

No c√≥digo, voc√™ pode ajustar a quantidade de dados:

```python
# Configura√ß√µes de volume
NUM_ENDERECOS = 10000
NUM_ODONTOLOGISTAS = 50
NUM_PACIENTES = 20000
NUM_PROCEDIMENTOS = 200
NUM_AGENDAMENTOS = 30000
NUM_CONSULTAS = 25000
NUM_PAGAMENTOS = 25000
NUM_LOGS_PAGAMENTO = 30000
```

## Processo de Execu√ß√£o

### 1. Prepara√ß√£o do Ambiente

```bash
# Verificar conex√£o com banco
python scripts/teste_db.py

# Executar gerador
python scripts/gerador_dados.py
```

### 2. Fluxo de Execu√ß√£o

1. **Inicializa√ß√£o**
   - Carrega vari√°veis de ambiente
   - Conecta ao banco PostgreSQL
   - Configura Azure Storage (se dispon√≠vel)

2. **Prepara√ß√£o do Banco**
   - Cria estrutura de tabelas
   - Limpa dados existentes
   - Configura constraints

3. **Gera√ß√£o de Dados**
   - Gera dados para cada entidade
   - Mant√©m integridade referencial
   - Aplica regras de neg√≥cio

4. **Persist√™ncia**
   - Insere dados no banco PostgreSQL
   - Exporta para CSV local (`data/raw/`)
   - Upload para Azure Storage (se configurado)

5. **Valida√ß√£o**
   - Verifica integridade dos dados
   - Gera relat√≥rio de contagem
   - Registra logs de sucesso/erro

### 3. Sa√≠das Geradas

#### Arquivos Locais
```
data/raw/
‚îú‚îÄ‚îÄ agendamento.csv
‚îú‚îÄ‚îÄ consulta.csv
‚îú‚îÄ‚îÄ consulta_procedimento.csv
‚îú‚îÄ‚îÄ endereco.csv
‚îú‚îÄ‚îÄ log_pagamento.csv
‚îú‚îÄ‚îÄ odontologista.csv
‚îú‚îÄ‚îÄ paciente.csv
‚îú‚îÄ‚îÄ pagamento.csv
‚îú‚îÄ‚îÄ procedimento.csv
‚îî‚îÄ‚îÄ tipo_pagamento.csv
```

#### Banco PostgreSQL
- Tabelas populadas com dados
- √çndices e constraints aplicados
- Dados prontos para an√°lise

#### Azure Storage (se configurado)
```
landingzone/
‚îî‚îÄ‚îÄ raw/
    ‚îú‚îÄ‚îÄ agendamento.csv
    ‚îú‚îÄ‚îÄ consulta.csv
    ‚îî‚îÄ‚îÄ ... (outros arquivos)
```

## Logs e Monitoramento

### Exemplo de Log de Execu√ß√£o

```
2024-12-25 10:30:15 - INFO - Iniciando gera√ß√£o de dados...
2024-12-25 10:30:16 - INFO - Conectado ao banco PostgreSQL
2024-12-25 10:30:17 - INFO - Azure Storage configurado
2024-12-25 10:30:18 - INFO - Criando e limpando tabelas...
2024-12-25 10:30:25 - INFO - Gerando 10000 endere√ßos...
2024-12-25 10:30:28 - INFO - Gerando 50 odontologistas...
2024-12-25 10:30:30 - INFO - ‚úÖ Dados inseridos com sucesso no banco
2024-12-25 10:30:32 - INFO - ‚úÖ CSVs exportados para data/raw/
2024-12-25 10:30:35 - INFO - ‚úÖ Upload para Azure Storage conclu√≠do
2024-12-25 10:30:35 - INFO - üéâ Processo conclu√≠do com sucesso!
```

## Tratamento de Erros

### Problemas Comuns

1. **Erro de Conex√£o com Banco**
   ```bash
   ERROR - Erro ao conectar ao banco: connection refused
   # Solu√ß√£o: Verificar se PostgreSQL est√° rodando
   docker-compose -f docker/docker-compose.yml up -d
   ```

2. **Erro do Azure Storage**
   ```bash
   WARNING - Azure Storage n√£o configurado, pulando upload
   # Solu√ß√£o: Configurar AZURE_STORAGE_CONNECTION_STRING no .env
   ```

3. **Erro de Depend√™ncias**
   ```bash
   ModuleNotFoundError: No module named 'azure'
   # Solu√ß√£o: Instalar depend√™ncias
   pip install -r requirements.txt
   ```

## Para Executar

```bash
# Execu√ß√£o simples
python scripts/gerador_dados.py

# Com logs detalhados
python scripts/gerador_dados.py 2>&1 | tee gerador.log

# Verificar resultados
ls -la data/raw/
psql -h localhost -U root -d clinica_odonto -c "SELECT COUNT(*) FROM paciente;"
```

Este processo garante que tenhamos uma base s√≥lida de dados para alimentar todo o pipeline ETL, desde a camada Landing at√© o Data Warehouse final.